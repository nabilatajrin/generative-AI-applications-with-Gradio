{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# L3: Image generation app ðŸŽ¨",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Load your HF API key and relevant Python libraries",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import os\nimport io\nimport IPython.display\nfrom PIL import Image\nimport base64 \nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\nhf_api_key = os.environ['HF_API_KEY']",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Helper function\nimport requests, json\n\n#Text-to-image endpoint\ndef get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n    headers = {\n      \"Authorization\": f\"Bearer {hf_api_key}\",\n      \"Content-Type\": \"application/json\"\n    }   \n    data = { \"inputs\": inputs }\n    if parameters is not None:\n        data.update({\"parameters\": parameters})\n    response = requests.request(\"POST\",\n                                ENDPOINT_URL,\n                                headers=headers,\n                                data=json.dumps(data))\n    return json.loads(response.content.decode(\"utf-8\"))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Building an image generation app ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### How about running it locally?\nThe code would look very similar if you were running it locally instead of from an API.\n```py\nfrom diffusers import DiffusionPipeline\n\npipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n\ndef get_completion(prompt):\n    return pipeline(prompt).images[0]    \n```",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "prompt = \"a dog in a park\"\n\nresult = get_completion(prompt)\nIPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Generating with `gr.Interface()`",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import gradio as gr \n\n#A helper function to convert the PIL image to base64\n#so you can send it to the API\ndef base64_to_pil(img_base64):\n    base64_decoded = base64.b64decode(img_base64)\n    byte_stream = io.BytesIO(base64_decoded)\n    pil_image = Image.open(byte_stream)\n    return pil_image\n\ndef generate(prompt):\n    output = get_completion(prompt)\n    result_image = base64_to_pil(output)\n    return result_image\n\ngr.close_all()\ndemo = gr.Interface(fn=generate,\n                    inputs=[gr.Textbox(label=\"Your prompt\")],\n                    outputs=[gr.Image(label=\"Result\")],\n                    title=\"Image Generation with Stable Diffusion\",\n                    description=\"Generate any image with Stable Diffusion\",\n                    allow_flagging=\"never\",\n                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n\ndemo.launch(share=True, server_port=int(os.environ['PORT1']))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "demo.close()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Building a more advanced interface",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import gradio as gr \n\n#A helper function to convert the PIL image to base64 \n# so you can send it to the API\ndef base64_to_pil(img_base64):\n    base64_decoded = base64.b64decode(img_base64)\n    byte_stream = io.BytesIO(base64_decoded)\n    pil_image = Image.open(byte_stream)\n    return pil_image\n\ndef generate(prompt, negative_prompt, steps, guidance, width, height):\n    params = {\n        \"negative_prompt\": negative_prompt,\n        \"num_inference_steps\": steps,\n        \"guidance_scale\": guidance,\n        \"width\": width,\n        \"height\": height\n    }\n    \n    output = get_completion(prompt, params)\n    pil_image = base64_to_pil(output)\n    return pil_image\n\ngr.close_all()\ndemo = gr.Interface(fn=generate,\n                    inputs=[\n                        gr.Textbox(label=\"Your prompt\"),\n                        gr.Textbox(label=\"Negative prompt\"),\n                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                                 info=\"In how many steps will the denoiser denoise the image?\"),\n                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n                                  info=\"Controls how much the text prompt influences the result\"),\n                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n                    ],\n                    outputs=[gr.Image(label=\"Result\")],\n                    title=\"Image Generation with Stable Diffusion\",\n                    description=\"Generate any image with Stable Diffusion\",\n                    allow_flagging=\"never\"\n                    )\n\ndemo.launch(share=True, server_port=int(os.environ['PORT2']))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "demo.close()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## `gr.Blocks()` to the rescue!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "with gr.Blocks() as demo:\n    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n    prompt = gr.Textbox(label=\"Your prompt\")\n    with gr.Row():\n        with gr.Column():\n            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                      info=\"In many steps will the denoiser denoise the image?\")\n            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n                      info=\"Controls how much the text prompt influences the result\")\n            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n            btn = gr.Button(\"Submit\")\n        with gr.Column():\n            output = gr.Image(label=\"Result\")\n\n    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\ngr.close_all()\ndemo.launch(share=True, server_port=int(os.environ['PORT3']))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "with gr.Blocks() as demo:\n    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n    with gr.Row():\n        with gr.Column(scale=4):\n            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n        with gr.Column(scale=1, min_width=50):\n            btn = gr.Button(\"Submit\") #Submit button side by side!\n    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n            with gr.Row():\n                with gr.Column():\n                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n                      info=\"In many steps will the denoiser denoise the image?\")\n                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n                      info=\"Controls how much the text prompt influences the result\")\n                with gr.Column():\n                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n    output = gr.Image(label=\"Result\") #Move the output up too\n            \n    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n\ngr.close_all()\ndemo.launch(share=True, server_port=int(os.environ['PORT4']))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "gr.close_all()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}